{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install labelme \n",
    "#!pip -q install uuid\n",
    "#!pip -q install albumentations \n",
    "#!pip -q install autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2 \n",
    "import utils\n",
    "print(\"worked\")\n",
    "\n",
    "len(os.listdir('data/images/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde3dd95",
   "metadata": {},
   "source": [
    "## creating images Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def capture_imgs(img_num, path):\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    num = 0\n",
    "        \n",
    "    while(num < img_num):\n",
    "        #*read img\n",
    "        ret, frame = cap.read() \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            print(f'collecting image {num}')\n",
    "            #*create path for the read img\n",
    "            img_name = os.path.join(path, f\"{str(uuid.uuid1())}.jpg\")\n",
    "            #* writing the img\n",
    "            cv2.imwrite(img_name, frame) \n",
    "            num +=1\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de961c",
   "metadata": {},
   "source": [
    "## Labeling with labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2817562",
   "metadata": {},
   "source": [
    "## Building Dataset and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ec53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## limiting GPU memory growth - avoid OOM\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# #gpus\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5827a5a1",
   "metadata": {},
   "source": [
    "### loading images into TF pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e202bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* loading images as bytes and decoding them\n",
    "def load_image(x):\n",
    "    byte_img  = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img, channels=3)\n",
    "    return img\n",
    "\n",
    "images = tf.data.Dataset.list_files('data/images/*.jpg', shuffle=False)\n",
    "#* testing\n",
    "print(images.as_numpy_iterator().next(), len(list(images.as_numpy_iterator())))\n",
    "\n",
    "#* using map to load images\n",
    "images= images.map(load_image)\n",
    "images = images.batch(4)\n",
    "test_img = images.as_numpy_iterator().next()\n",
    "\n",
    "\n",
    "fig = plt.subplots(figsize=(10, 10))\n",
    "for i in range(test_img.shape[0]):\n",
    "    plt.subplot(1, test_img.shape[0], i+1)\n",
    "    plt.imshow(test_img[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "088d2032",
   "metadata": {},
   "source": [
    "### Splinting Dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def retrieve_emotion(x):\n",
    "    json_path = x.replace(\"jpg\", \"json\").replace(\"images\", \"labels\")\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "            emotion = data[\"shapes\"][0][\"label\"]\n",
    "            return emotion\n",
    "    else:\n",
    "        return \"no face\"\n",
    "\n",
    "\n",
    "def retrieve_bbox(x):\n",
    "    json_path = x.replace(\"jpg\", \"json\").replace(\"images\", \"labels\")\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "            bbox = data[\"shapes\"][0][\"points\"]\n",
    "            return bbox\n",
    "    else:\n",
    "        return [[0, 0], [0.0001, 0.00001]]\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(os.listdir(\"data/images/\"), columns=[\"images\"])\n",
    "data_df[\"images\"] = data_df[\"images\"].apply(lambda x: os.path.join(\"data/images/\", x))\n",
    "data_df[\"labels\"] = data_df[\"images\"].apply(retrieve_emotion)\n",
    "data_df[\"bbox\"] = data_df[\"images\"].apply(retrieve_bbox)\n",
    "data_df.to_csv(\"data/data.csv\", index=False)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df, _, _ = train_test_split(\n",
    "    data_df,\n",
    "    data_df[\"labels\"],\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=data_df[\"labels\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "print(train_df.shape, val_df.shape)\n",
    "train_df[\"labels\"].value_counts() / len(train_df), val_df[\"labels\"].value_counts() / len(val_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f089b72",
   "metadata": {},
   "source": [
    "### Augmenting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "\n",
    "augmentor = alb.Compose(\n",
    "    [\n",
    "        alb.RandomCrop(450, 450),\n",
    "        alb.HorizontalFlip(p=0.5),\n",
    "        alb.VerticalFlip(p=0.5),\n",
    "        alb.RandomBrightnessContrast(p=0.2),\n",
    "        alb.RandomGamma(p=0.2),\n",
    "        alb.RGBShift(p=0.2),\n",
    "    ],\n",
    "    bbox_params=alb.BboxParams(format=\"albumentations\", label_fields=[\"class_labels\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(df:pd.DataFrame, split: str, num_copies = 120):\n",
    "    aug_imgs_list = []\n",
    "    aug_coords_list = []\n",
    "    aug_label_list = []\n",
    "    if not os.path.isdir(f'aug_data\\{split}\\images'):\n",
    "        os.makedirs(f'aug_data\\{split}\\images')\n",
    "    if (len(os.listdir(f'aug_data\\{split}\\images')) == 0):\n",
    "        for item in range(len(df)):\n",
    "            path = df.iloc[item]['images']\n",
    "            img_name = path.split('/')[-1].split(\".\")[0]\n",
    "            label = df.iloc[item]['labels']\n",
    "            img = cv2.imread(path)\n",
    "            coords = utils.cord_fixer(df.iloc[item]['bbox'], img)\n",
    "            for x in range(num_copies):\n",
    "                augmented = augmentor(image=img, bboxes=coords, class_labels=[label])\n",
    "                cv2.imwrite(f'aug_data/{split}/images/{img_name}_{x}.jpg', augmented['image'])\n",
    "                aug_imgs_list.append(f'aug_data/{split}/images/{img_name}_{x}.jpg')\n",
    "                \n",
    "                try:\n",
    "                    aug_label_list.append(augmented['class_labels'][0])\n",
    "                    aug_coords  = augmented['bboxes'][0]\n",
    "                    #print(type(aug_coords))\n",
    "                    aug_coords_list.append(aug_coords)\n",
    "                except:\n",
    "                    aug_label_list.append(label)\n",
    "                    aug_coords_list.append((0,0,0,0))\n",
    "                    \n",
    "        aug_df = pd.DataFrame({'images': aug_imgs_list, 'labels': aug_label_list, 'bbox': aug_coords_list})\n",
    "        aug_df.to_csv(f'aug_data/{split}/train_data.csv', index=False)\n",
    "    else:\n",
    "        print(f'{split} data already augmented')\n",
    "\n",
    "\n",
    "augment_data(train_df, 'train', num_copies=125)\n",
    "augment_data(val_df, 'val', num_copies=15)\n",
    "\n",
    "aug_train_df = pd.read_csv('aug_data/train/train_data.csv')\n",
    "aug_train_df['bbox'] = aug_train_df['bbox'].apply(lambda x: eval(x))\n",
    "\n",
    "aug_val_df = pd.read_csv('aug_data/val/train_data.csv')\n",
    "aug_val_df['bbox'] = aug_val_df['bbox'].apply(lambda x: eval(x))\n",
    "\n",
    "\n",
    "aug_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = aug_train_df.iloc[1250]\n",
    "img = cv2.imread(sample['images'])\n",
    "coords = sample['bbox']\n",
    "img_label = sample['labels']\n",
    "\n",
    "cv2.rectangle(\n",
    "    img,\n",
    "    (\n",
    "        int(coords[0] * img.shape[0]),\n",
    "        int(coords[1] * img.shape[1]),\n",
    "    ),\n",
    "    (\n",
    "        int(coords[2] * img.shape[0]),\n",
    "        int(coords[3] * img.shape[1]),\n",
    "    ),\n",
    "    (0, 255, 0),\n",
    "    2,\n",
    ")\n",
    "print(img_label)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6938df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_labeled_img(path):\n",
    "    label_path = path.replace('images', 'labels').replace('jpg', 'json')\n",
    "    coords = json.load(open(label_path))['shapes'][0]['points']\n",
    "    img = cv2.imread(path)\n",
    "    coords = utils.cord_fixer(coords, img)\n",
    "    cv2.rectangle(\n",
    "        img = img,\n",
    "        pt1=(int(coords[0][0] * img.shape[1]), int(coords[0][1] * img.shape[0])),\n",
    "        pt2=(int(coords[0][2] * img.shape[1]), int(coords[0][3] * img.shape[0])),\n",
    "        color=(0, 255, 0),\n",
    "        thickness=2,\n",
    "    )\n",
    "    plt.imshow(img)\n",
    "\n",
    "path = r'data\\images\\99ee658a-e836-11ed-89c2-60189528f842.jpg'\n",
    "show_labeled_img(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80885ab4",
   "metadata": {},
   "source": [
    "## Create Augmented Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    byte_img  = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img, channels=3)\n",
    "\n",
    "    return img\n",
    "\n",
    "class_dict = {\n",
    "    'no face' : 0,\n",
    "    'happy' : 1,\n",
    "    'sad' : 2,\n",
    "    'natural' : 3,\n",
    "    'surprised' : 4,\n",
    "    'angry' : 5,\n",
    "}\n",
    "\n",
    "reverse_dict  = {v:k for k,v in class_dict.items()}\n",
    "\n",
    "aug_train_df = pd.read_csv('aug_data/train/train_data.csv')\n",
    "\n",
    "def load_dataset_from_df(df, class_dict = class_dict ):\n",
    "    #aug_train_df['bbox'] = aug_train_df['bbox'].apply(lambda x: eval(x))\n",
    "    df['bbox'] = df['bbox'].apply(lambda x:eval(x))\n",
    "    df['xmin'] = df['bbox'].apply(lambda x: x[0]).astype('float32')\n",
    "    df['ymin'] = df['bbox'].apply(lambda x: x[1]).astype('float32')\n",
    "    df['xmax'] = df['bbox'].apply(lambda x: x[2]).astype('float32')\n",
    "    df['ymax'] = df['bbox'].apply(lambda x: x[3]).astype('float32')\n",
    "    df['labels'] = df['labels'].apply(lambda x: class_dict[x]).astype('float32')\n",
    "\n",
    "    #* one hot encoding\n",
    "    onehot_labels = tf.keras.utils.to_categorical(df['labels'], num_classes=6)\n",
    "    onehot_labels = tf.convert_to_tensor(onehot_labels, dtype=tf.float32)\n",
    "\n",
    "    dataset_label = tf.data.Dataset.from_tensor_slices(onehot_labels)\n",
    "    # aug_train_df.drop('bbox', axis=1, inplace=True)\n",
    "    dataset_images = tf.data.Dataset.from_tensor_slices(df[['images']])\n",
    "    dataset_images = dataset_images.map(lambda x: load_image(x[0]))\n",
    "    dataset_images = dataset_images.map(lambda x : tf.image.resize(x, (120, 120)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset_images = dataset_images.map(lambda x : x/255, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    data_set_coords = tf.data.Dataset.from_tensor_slices((df[['xmin', 'ymin', 'xmax', 'ymax']]))\n",
    "    dataset = tf.data.Dataset.zip((dataset_images, dataset_label , data_set_coords))\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset_from_df(aug_train_df)\n",
    "#* for prediction\n",
    "## reverse_dict[y[0].argmax()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29395b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_augmented_data_deprecated(split, augmentor, n_img):\n",
    "    for image in os.listdir(os.path.join('data', split, 'images')):\n",
    "        img  = cv2.imread(os.path.join('data', split, 'images', image))\n",
    "        coords = [0, 0 , 0.000001, 0.000001]\n",
    "        label_path = os.path.join('data', split, 'labels', image.split('.')[0]+'.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label =json.load(f)\n",
    "                coords = label['shapes'][0]['points']\n",
    "                coords = utils.cord_fixer(coords, img)\n",
    "                img_label  = label['shapes'][0]['label']\n",
    "        try :\n",
    "            for x in range (n_img):\n",
    "                #* saving the augmented image\n",
    "                augmented  = augmentor(image=img, bboxes =coords, class_labels = [img_label])\n",
    "                cv2.imwrite(os.path.join('aug_data', split, 'images', image.split('.')[0]+f'_{x}.jpg'), augmented['image'])\n",
    "                #* saving the augmented label\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0:\n",
    "                        annotation['bbox'] = [0.0, 0.0, 0.0, 0.0]\n",
    "                        annotation['class'] = 'no face'\n",
    "                    else:\n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = augmented['class_labels'][0]\n",
    "                else:\n",
    "                    annotation['bbox'] = [0.0, 0.0, 0.0, 0.0]\n",
    "                    annotation['class'] = 'no face'\n",
    "                    \n",
    "                with open(os.path.join('aug_data', split, 'labels', image.split('.')[0] + f'_{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "                    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2ae9a65",
   "metadata": {},
   "source": [
    "### Preparing Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    byte_img  = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def _prepare_data_deprecated(path):\n",
    "    images = tf.data.Dataset.list_files(path, shuffle=False)\n",
    "    images = images.map(utils.load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    images = images.map(lambda x : tf.image.resize(x, (120, 120)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    images = images.map(lambda x : x/255, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return images\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aae236df",
   "metadata": {},
   "source": [
    "## combining labels and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fe659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_deprecated(images, labels):\n",
    "    data = tf.data.Dataset.zip((images, labels))\n",
    "    data = data.shuffle(1000).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "# train = _combine(train_images, train_label)\n",
    "# test = _combine(test_images, test_label)\n",
    "# val = _combine(val_images, val_label)\n",
    "# sample_iterator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d934779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset.batch(4)))\n",
    "img = sample[0][0].numpy()\n",
    "label = sample[1][0].numpy()\n",
    "label = reverse_dict[label.argmax()]\n",
    "coords = sample[2][0].numpy()\n",
    "\n",
    "cv2.rectangle(\n",
    "    img,\n",
    "    (int(coords[0] * img.shape[0]), int(coords[1] * img.shape[1])),\n",
    "    (int(coords[2] * img.shape[0]), int(coords[3] * img.shape[1])),\n",
    "    (0, 255, 0),\n",
    "    2,\n",
    ")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(label)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
