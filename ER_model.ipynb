{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#* autoreload to reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#* import custom modules\n",
    "#from process import *\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    byte_img  = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img, channels=3)\n",
    "\n",
    "    return img\n",
    "\n",
    "class_dict = {\n",
    "    'no face' : 0,\n",
    "    'happy' : 1,\n",
    "    'sad' : 2,\n",
    "    'natural' : 3,\n",
    "    'surprised' : 4,\n",
    "    'angry' : 5,\n",
    "}\n",
    "\n",
    "reverse_dict  = {v:k for k,v in class_dict.items()}\n",
    "\n",
    "aug_train_df = pd.read_csv('aug_data/train/train_data.csv')\n",
    "aug_val_df = pd.read_csv('aug_data/val/val_data.csv')\n",
    "\n",
    "def load_dataset_from_df(df, class_dict = class_dict ):\n",
    "    #aug_train_df['bbox'] = aug_train_df['bbox'].apply(lambda x: eval(x))\n",
    "    df['bbox'] = df['bbox'].apply(lambda x:eval(x))\n",
    "    df['xmin'] = df['bbox'].apply(lambda x: x[0]).astype('float32')\n",
    "    df['ymin'] = df['bbox'].apply(lambda x: x[1]).astype('float32')\n",
    "    df['xmax'] = df['bbox'].apply(lambda x: x[2]).astype('float32')\n",
    "    df['ymax'] = df['bbox'].apply(lambda x: x[3]).astype('float32')\n",
    "    df['labels'] = df['labels'].apply(lambda x: class_dict[x]).astype('float32')\n",
    "\n",
    "    #* one hot encoding\n",
    "    onehot_labels = tf.keras.utils.to_categorical(df['labels'], num_classes=6)\n",
    "    onehot_labels = tf.convert_to_tensor(onehot_labels, dtype=tf.float32)\n",
    "\n",
    "    dataset_label = tf.data.Dataset.from_tensor_slices(onehot_labels)\n",
    "    # aug_train_df.drop('bbox', axis=1, inplace=True)\n",
    "    dataset_images = tf.data.Dataset.from_tensor_slices(df[['images']])\n",
    "    dataset_images = dataset_images.map(lambda x: load_image(x[0]))\n",
    "    dataset_images = dataset_images.map(lambda x : tf.image.resize(x, (120, 120)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset_images = dataset_images.map(lambda x : x/255, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    data_set_coords = tf.data.Dataset.from_tensor_slices((df[['xmin', 'ymin', 'xmax', 'ymax']]))\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((dataset_label , data_set_coords))\n",
    "    dataset = tf.data.Dataset.zip((dataset_images, dataset ))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train = load_dataset_from_df(aug_train_df)\n",
    "#* for prediction\n",
    "## reverse_dict[y[0].argmax()]\n",
    "val = load_dataset_from_df(aug_val_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (120, 120)\n",
    "batch_size = 8\n",
    "train = train.batch(batch_size).prefetch(tf.data.AUTOTUNE).shuffle(1000)\n",
    "val = val.batch(batch_size).prefetch(tf.data.AUTOTUNE).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(size=size):\n",
    "    input_layer = Input(shape=(size[0],size[1], 3))\n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "\n",
    "    #* 1 for classification\n",
    "    f1 = tf.keras.layers.GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1)\n",
    "    class2 = Dense(6, activation='softmax')(class1)\n",
    "    # class2 = tf.cast(class2, tf.float16)\n",
    "\n",
    "    #* 4 for bounding box\n",
    "    f2 = tf.keras.layers.GlobalAveragePooling2D()(vgg)\n",
    "    reggress1 = Dense(2048, activation='relu')(f2)\n",
    "    reggress2 = Dense(4, activation='sigmoid')(reggress1)\n",
    "    #reggress2 = tf.cast(reggress2, tf.float16)\n",
    "\n",
    "    face_tracker = Model(inputs = input_layer, outputs = [class2, reggress2])\n",
    "\n",
    "    return face_tracker\n",
    "\n",
    "face_tracker = build_model()\n",
    "#face_tracker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train) // batch_size\n",
    "lr_decay = (1./0.75 - 1) / (batches_per_epoch)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, y_pred):\n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:, :2] - y_pred[:, :2]))\n",
    "    \n",
    "    try :\n",
    "        h_true = y_true[:, 3]  - y_true[:, 1]\n",
    "        w_true = y_true[:, 2]  - y_true[:, 0]\n",
    "        \n",
    "        h_pred = y_pred[:, 3]  - y_pred[:, 1]\n",
    "        w_pred = y_pred[:, 2]  - y_pred[:, 0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(y_true)\n",
    "        print(y_pred)\n",
    "        raise e\n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true - h_pred))\n",
    "    # delta_size = tf.reduce_sum(tf.square(tf.sqrt(w_true) - tf.sqrt(w_pred)) + tf.square(tf.sqrt(h_true) - tf.sqrt(h_pred)))    \n",
    "    \n",
    "    return delta_coord + 0.5*delta_size\n",
    "\n",
    "classification_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "regression_loss = localization_loss\n",
    "\n",
    "# def total_loss (y_true, y_pred):\n",
    "#     class_loss = tf.keras.losses.BinaryCrossentropy()(y_true[0], y_pred[0])\n",
    "#     regression_loss = localization_loss(y_true[1], y_pred[1])\n",
    "#     return class_loss + regression_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTracker(Model):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "        self.coord_track = []\n",
    "        \n",
    "    def compile(self, optimizer, class_loss, regression_loss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.optimizer = optimizer\n",
    "        self.class_loss = class_loss\n",
    "        self.regression_loss = regression_loss\n",
    "        \n",
    "    def train_step(self, batch, **kwargs):\n",
    "        x, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #* predict\n",
    "            classes, coords = self.model(x, training=True)\n",
    "            #self.coord_track.append(coords)\n",
    "            #* calculate loss\n",
    "            batch_class_loss = self.class_loss(y[0], classes)\n",
    "            batch_regression_loss = self.regression_loss(y[1], coords)\n",
    "            \n",
    "            #* total loss\n",
    "            total_loss = 2*batch_regression_loss + batch_class_loss\n",
    "            \n",
    "            #* get gradients\n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "            \n",
    "        #* update weights\n",
    "        self.optimizer.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        return {'loss': total_loss, 'class_loss': batch_class_loss, 'regression_loss': batch_regression_loss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs):\n",
    "        x, y = batch\n",
    "        \n",
    "        classes, coords = self.model(x, training=False)\n",
    "        batch_class_loss = self.class_loss(y[0], classes)\n",
    "        batch_regression_loss = self.regression_loss(y[1], coords)\n",
    "        \n",
    "        total_loss = batch_regression_loss +  batch_class_loss\n",
    "        return {'loss': total_loss, 'class_loss': batch_class_loss, 'regression_loss': batch_regression_loss}\n",
    "        \n",
    "    def call(self, x, **kwargs):\n",
    "        return self.model(x, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* save best model\n",
    "import os\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "checkpoint_path = \"models/ER_model.h5\"\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "#* early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=25,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model.fit(train, epochs=500, validation_data=val, callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_tracker = build_model()\n",
    "model = FaceTracker(face_tracker)\n",
    "model.compile(optimizer=opt, class_loss=classification_loss, regression_loss=regression_loss)\n",
    "model.built = True\n",
    "model.load_weights('models/ER_model.h5')\n",
    "\n",
    "class_dict = {\n",
    "    'no face' : 0,\n",
    "    'happy' : 1,\n",
    "    'sad' : 2,\n",
    "    'natural' : 3,\n",
    "    'surprised' : 4,\n",
    "    'angry' : 5,\n",
    "}\n",
    "\n",
    "reverse_dict  = {v:k for k,v in class_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'aug_data\\val\\images\\3c86f828-e836-11ed-a2ea-60189528f842_0.jpg'\n",
    "img  = cv2.imread(path)\n",
    "resized_img = np.expand_dims(cv2.resize(img, (120, 120))/255.0, axis=0)\n",
    "pred = model.predict(resized_img)\n",
    "\n",
    "cv2.rectangle(\n",
    "    img, \n",
    "    pt1= (int(pred[1][0][0]*img.shape[1]), int(pred[1][0][1]*img.shape[0])),\n",
    "    pt2= (int(pred[1][0][2]*img.shape[1]), int(pred[1][0][3]*img.shape[0])),\n",
    "    color=(0, 255, 0),  \n",
    "    thickness=2\n",
    ")\n",
    "plt.title(reverse_dict[pred[0].argmax(axis=1)[0]])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import *\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#* autoreload to reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "face_tracker = build_model()\n",
    "model = FaceTracker(face_tracker)\n",
    "#model.compile(optimizer=opt, class_loss=classification_loss, regression_loss=regression_loss)\n",
    "model.built = True\n",
    "model.load_weights('models/ER_model.h5')\n",
    "\n",
    "class_dict = {\n",
    "    'no face' : 0,\n",
    "    'happy' : 1,\n",
    "    'sad' : 2,\n",
    "    'natural' : 3,\n",
    "    'surprised' : 4,\n",
    "    'angry' : 5,\n",
    "}\n",
    "\n",
    "reverse_dict  = {v:k for k,v in class_dict.items()}\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
